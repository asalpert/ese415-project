{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f96f268-eb20-4726-85b9-f3d02f976681",
   "metadata": {},
   "source": [
    "# ESE 415 Final Project - Analyzing Data Scientist Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a3463-df16-4743-8371-1d31e5ca38ba",
   "metadata": {},
   "source": [
    "## By: Abigail Alpert and Kevin Yan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f16705-6c1f-49f2-a1cb-967e2903f7c9",
   "metadata": {},
   "source": [
    "# Data exploration and preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04919967-5d6c-45cb-ac3e-eb99404e4121",
   "metadata": {},
   "source": [
    "### Dataset Columns\n",
    "1. **work_year** : The year the salary was paid.\n",
    "\n",
    "2. **experience_level** : The experience level in the job during the year\n",
    "\n",
    "3. **employment_type** : The type of employment for the role\n",
    "\n",
    "4. **job_title** : The role worked in during the year.\n",
    "\n",
    "5. **salary** : The total gross salary amount paid.\n",
    "\n",
    "6. **salary_currency** : The currency of the salary paid as an ISO 4217 currency code.\n",
    "\n",
    "7. **salaryinusd** : The salary in USD\n",
    "\n",
    "8. **employee_residence** : Employee's primary country of residence in during the work year as an ISO 3166 country code.\n",
    "\n",
    "9. **remote_ratio** : The overall amount of work done remotely\n",
    "\n",
    "10. **company_location** : The country of the employer's main office or contracting branch\n",
    "\n",
    "11. **company_size** : The median number of people that worked for the company during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca987961-a3ca-488b-865d-34eec2ca4df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0541b066-b106-43d9-9ddc-e4beff7579b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>79833</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>260000</td>\n",
       "      <td>USD</td>\n",
       "      <td>260000</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>85000</td>\n",
       "      <td>GBP</td>\n",
       "      <td>109024</td>\n",
       "      <td>GB</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000</td>\n",
       "      <td>USD</td>\n",
       "      <td>20000</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>154000</td>\n",
       "      <td>USD</td>\n",
       "      <td>154000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000</td>\n",
       "      <td>USD</td>\n",
       "      <td>126000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000</td>\n",
       "      <td>USD</td>\n",
       "      <td>129000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2022</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>200000</td>\n",
       "      <td>USD</td>\n",
       "      <td>200000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     work_year experience_level employment_type                   job_title  \\\n",
       "0         2020               MI              FT              Data Scientist   \n",
       "1         2020               SE              FT  Machine Learning Scientist   \n",
       "2         2020               SE              FT           Big Data Engineer   \n",
       "3         2020               MI              FT        Product Data Analyst   \n",
       "4         2020               SE              FT   Machine Learning Engineer   \n",
       "..         ...              ...             ...                         ...   \n",
       "602       2022               SE              FT               Data Engineer   \n",
       "603       2022               SE              FT               Data Engineer   \n",
       "604       2022               SE              FT                Data Analyst   \n",
       "605       2022               SE              FT                Data Analyst   \n",
       "606       2022               MI              FT                AI Scientist   \n",
       "\n",
       "     salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0     70000             EUR          79833                 DE             0   \n",
       "1    260000             USD         260000                 JP             0   \n",
       "2     85000             GBP         109024                 GB            50   \n",
       "3     20000             USD          20000                 HN             0   \n",
       "4    150000             USD         150000                 US            50   \n",
       "..      ...             ...            ...                ...           ...   \n",
       "602  154000             USD         154000                 US           100   \n",
       "603  126000             USD         126000                 US           100   \n",
       "604  129000             USD         129000                 US             0   \n",
       "605  150000             USD         150000                 US           100   \n",
       "606  200000             USD         200000                 IN           100   \n",
       "\n",
       "    company_location company_size  \n",
       "0                 DE            L  \n",
       "1                 JP            S  \n",
       "2                 GB            M  \n",
       "3                 HN            S  \n",
       "4                 US            L  \n",
       "..               ...          ...  \n",
       "602               US            M  \n",
       "603               US            M  \n",
       "604               US            M  \n",
       "605               US            M  \n",
       "606               US            L  \n",
       "\n",
       "[607 rows x 11 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ds_salaries.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3aec3-3477-4957-80d1-b75236fb0118",
   "metadata": {},
   "source": [
    "First off, basic data cleaning (dropping duplicates and NA's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37732a89-4d8b-4991-88a0-4c9d6ed16fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['salary_in_usd']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a78fd2-be42-47f4-9a33-e250ad4c36c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let's create a couple flags/binary variables that could be useful for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1674a151-994c-4a89-aee3-ebd38db79f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['is_manager'] = df['job_title'].str.contains('Manager|Lead|Director|Head', case=False).astype(int)\n",
    "df['is_remote'] = (df['remote_ratio'] == 100).astype(int)\n",
    "df['is_hybrid'] = ((df['remote_ratio'] > 0) & (df['remote_ratio'] < 100)).astype(int)\n",
    "df['same_country'] = (df['employee_residence'] == df['company_location']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6011c08f-7ca0-47e8-84a7-24bb9b84f603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Job Titles: 50\n",
      "Unique Employee Residences: 57\n",
      "Unique Company Locations: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Job Titles:\",len(standardized_df['job_title'].unique()))\n",
    "print(\"Unique Employee Residences:\",len(standardized_df['employee_residence'].unique()))\n",
    "print(\"Unique Company Locations:\",len(standardized_df['company_location'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b397d0-d112-499b-aed2-6f0105c52b2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Check if standardizing makes sense here. My concern is that it'll make our predictions hard to interpret </span>\n",
    "\n",
    "Let's standardize the numerical features to help the model converge faster. The different numerical features have very different magnitudes which could cause issues during gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e24c8183-8114-401a-a13a-ceb4f048220e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>is_manager</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>is_hybrid</th>\n",
       "      <th>same_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.956361</td>\n",
       "      <td>-0.167734</td>\n",
       "      <td>-0.426180</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EUR</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.956361</td>\n",
       "      <td>-0.048869</td>\n",
       "      <td>2.068630</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>USD</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.956361</td>\n",
       "      <td>-0.158350</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.487257</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>GBP</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.956361</td>\n",
       "      <td>-0.199014</td>\n",
       "      <td>-1.254701</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>HN</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.956361</td>\n",
       "      <td>-0.117686</td>\n",
       "      <td>0.545437</td>\n",
       "      <td>-0.487257</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.910939</td>\n",
       "      <td>-0.115183</td>\n",
       "      <td>0.600826</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.910939</td>\n",
       "      <td>-0.132700</td>\n",
       "      <td>0.213104</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.910939</td>\n",
       "      <td>-0.130823</td>\n",
       "      <td>0.254645</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.910939</td>\n",
       "      <td>-0.117686</td>\n",
       "      <td>0.545437</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.910939</td>\n",
       "      <td>-0.086406</td>\n",
       "      <td>1.237797</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>USD</td>\n",
       "      <td>IN</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    work_year    salary salary_in_usd remote_ratio experience_level  \\\n",
       "0   -1.956361 -0.167734     -0.426180    -1.710815               MI   \n",
       "1   -1.956361 -0.048869      2.068630    -1.710815               SE   \n",
       "2   -1.956361 -0.158350     -0.021966    -0.487257               SE   \n",
       "3   -1.956361 -0.199014     -1.254701    -1.710815               MI   \n",
       "4   -1.956361 -0.117686      0.545437    -0.487257               SE   \n",
       "..        ...       ...           ...          ...              ...   \n",
       "560  0.910939 -0.115183      0.600826     0.736300               SE   \n",
       "561  0.910939 -0.132700      0.213104     0.736300               SE   \n",
       "562  0.910939 -0.130823      0.254645    -1.710815               SE   \n",
       "563  0.910939 -0.117686      0.545437     0.736300               SE   \n",
       "564  0.910939 -0.086406      1.237797     0.736300               MI   \n",
       "\n",
       "    employment_type                   job_title salary_currency  \\\n",
       "0                FT              Data Scientist             EUR   \n",
       "1                FT  Machine Learning Scientist             USD   \n",
       "2                FT           Big Data Engineer             GBP   \n",
       "3                FT        Product Data Analyst             USD   \n",
       "4                FT   Machine Learning Engineer             USD   \n",
       "..              ...                         ...             ...   \n",
       "560              FT               Data Engineer             USD   \n",
       "561              FT               Data Engineer             USD   \n",
       "562              FT                Data Analyst             USD   \n",
       "563              FT                Data Analyst             USD   \n",
       "564              FT                AI Scientist             USD   \n",
       "\n",
       "    employee_residence company_location company_size is_manager is_remote  \\\n",
       "0                   DE               DE            L          0         0   \n",
       "1                   JP               JP            S          0         0   \n",
       "2                   GB               GB            M          0         0   \n",
       "3                   HN               HN            S          0         0   \n",
       "4                   US               US            L          0         0   \n",
       "..                 ...              ...          ...        ...       ...   \n",
       "560                 US               US            M          0         1   \n",
       "561                 US               US            M          0         1   \n",
       "562                 US               US            M          0         0   \n",
       "563                 US               US            M          0         1   \n",
       "564                 IN               US            L          0         1   \n",
       "\n",
       "    is_hybrid same_country  \n",
       "0           0            1  \n",
       "1           0            1  \n",
       "2           1            1  \n",
       "3           0            1  \n",
       "4           1            1  \n",
       "..        ...          ...  \n",
       "560         0            1  \n",
       "561         0            1  \n",
       "562         0            1  \n",
       "563         0            1  \n",
       "564         0            0  \n",
       "\n",
       "[565 rows x 15 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['work_year', 'salary', 'salary_in_usd', 'remote_ratio']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_standardized = preprocessor.fit_transform(df)\n",
    "\n",
    "all_feature_names = list(num_cols) + [\n",
    "    col for col in df.columns \n",
    "    if col not in num_cols\n",
    "]\n",
    "\n",
    "standardized_df = pd.DataFrame(X_standardized, columns=all_feature_names)\n",
    "\n",
    "standardized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6b048-8056-4f62-b37d-f89b16eea03f",
   "metadata": {},
   "source": [
    "Unfortunately, it seems like these categorical variables have many possibilities, so performing one-hot encoding on these columns may create too many columns to be feasible. We will have to find other ways to deal with these columns, as we believe that the job title will play a strong role in predicting salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7b239-938d-4226-8c88-a28a547c1c14",
   "metadata": {
    "tags": []
   },
   "source": [
    "With that being said, let's handle the lower-cardinal categorical features with one-hot encoding. Note that we ignore salary_currency as we do not think it will be predictive given we have the salary_in_usd column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5fd4d83-3d8c-4979-a5db-0e9ea73e80db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level_EN</th>\n",
       "      <th>experience_level_EX</th>\n",
       "      <th>experience_level_MI</th>\n",
       "      <th>experience_level_SE</th>\n",
       "      <th>employment_type_CT</th>\n",
       "      <th>employment_type_FL</th>\n",
       "      <th>employment_type_FT</th>\n",
       "      <th>employment_type_PT</th>\n",
       "      <th>company_size_L</th>\n",
       "      <th>company_size_M</th>\n",
       "      <th>...</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>company_location</th>\n",
       "      <th>is_manager</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>is_hybrid</th>\n",
       "      <th>same_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426180</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EUR</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.068630</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>USD</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.487257</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>GBP</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.254701</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>HN</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545437</td>\n",
       "      <td>-0.487257</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600826</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213104</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254645</td>\n",
       "      <td>-1.710815</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545437</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>USD</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.237797</td>\n",
       "      <td>0.736300</td>\n",
       "      <td>AI Scientist</td>\n",
       "      <td>USD</td>\n",
       "      <td>IN</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experience_level_EN experience_level_EX experience_level_MI  \\\n",
       "0                   0.0                 0.0                 1.0   \n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   0.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 1.0   \n",
       "4                   0.0                 0.0                 0.0   \n",
       "..                  ...                 ...                 ...   \n",
       "560                 0.0                 0.0                 0.0   \n",
       "561                 0.0                 0.0                 0.0   \n",
       "562                 0.0                 0.0                 0.0   \n",
       "563                 0.0                 0.0                 0.0   \n",
       "564                 0.0                 0.0                 1.0   \n",
       "\n",
       "    experience_level_SE employment_type_CT employment_type_FL  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   1.0                0.0                0.0   \n",
       "2                   1.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   1.0                0.0                0.0   \n",
       "..                  ...                ...                ...   \n",
       "560                 1.0                0.0                0.0   \n",
       "561                 1.0                0.0                0.0   \n",
       "562                 1.0                0.0                0.0   \n",
       "563                 1.0                0.0                0.0   \n",
       "564                 0.0                0.0                0.0   \n",
       "\n",
       "    employment_type_FT employment_type_PT company_size_L company_size_M  ...  \\\n",
       "0                  1.0                0.0            1.0            0.0  ...   \n",
       "1                  1.0                0.0            0.0            0.0  ...   \n",
       "2                  1.0                0.0            0.0            1.0  ...   \n",
       "3                  1.0                0.0            0.0            0.0  ...   \n",
       "4                  1.0                0.0            1.0            0.0  ...   \n",
       "..                 ...                ...            ...            ...  ...   \n",
       "560                1.0                0.0            0.0            1.0  ...   \n",
       "561                1.0                0.0            0.0            1.0  ...   \n",
       "562                1.0                0.0            0.0            1.0  ...   \n",
       "563                1.0                0.0            0.0            1.0  ...   \n",
       "564                1.0                0.0            1.0            0.0  ...   \n",
       "\n",
       "    salary_in_usd remote_ratio                   job_title salary_currency  \\\n",
       "0       -0.426180    -1.710815              Data Scientist             EUR   \n",
       "1        2.068630    -1.710815  Machine Learning Scientist             USD   \n",
       "2       -0.021966    -0.487257           Big Data Engineer             GBP   \n",
       "3       -1.254701    -1.710815        Product Data Analyst             USD   \n",
       "4        0.545437    -0.487257   Machine Learning Engineer             USD   \n",
       "..            ...          ...                         ...             ...   \n",
       "560      0.600826     0.736300               Data Engineer             USD   \n",
       "561      0.213104     0.736300               Data Engineer             USD   \n",
       "562      0.254645    -1.710815                Data Analyst             USD   \n",
       "563      0.545437     0.736300                Data Analyst             USD   \n",
       "564      1.237797     0.736300                AI Scientist             USD   \n",
       "\n",
       "    employee_residence company_location is_manager is_remote is_hybrid  \\\n",
       "0                   DE               DE          0         0         0   \n",
       "1                   JP               JP          0         0         0   \n",
       "2                   GB               GB          0         0         1   \n",
       "3                   HN               HN          0         0         0   \n",
       "4                   US               US          0         0         1   \n",
       "..                 ...              ...        ...       ...       ...   \n",
       "560                 US               US          0         1         0   \n",
       "561                 US               US          0         1         0   \n",
       "562                 US               US          0         0         0   \n",
       "563                 US               US          0         1         0   \n",
       "564                 IN               US          0         1         0   \n",
       "\n",
       "    same_country  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "560            1  \n",
       "561            1  \n",
       "562            1  \n",
       "563            1  \n",
       "564            0  \n",
       "\n",
       "[565 rows x 23 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_card_cat_features = [\n",
    "    'experience_level',  # EN, MI, SE, EX\n",
    "    'employment_type',   # FT, PT, CT, FL\n",
    "    'company_size',     # S, M, L\n",
    "]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), low_card_cat_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(standardized_df)\n",
    "\n",
    "\n",
    "cat_encoder = preprocessor.named_transformers_['cat']\n",
    "feature_names = cat_encoder.get_feature_names_out(low_card_cat_features)\n",
    "\n",
    "all_feature_names = list(feature_names) + [\n",
    "    col for col in standardized_df.columns \n",
    "    if col not in low_card_cat_features\n",
    "]\n",
    "\n",
    "processed_df = pd.DataFrame(X_processed, columns=all_feature_names)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4e8fd-28c6-47cb-a531-9fa410447364",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> we need to figure out how we'll handle the job_title and employee_residence columns </span>\n",
    "\n",
    "**job_title:** this feaure seems like it will be important, as we suspect samples with the same/similar job title to have more similar salaries.\n",
    "\n",
    "**employee_residence:** this feature seems important, because salary often relates to cost of living (ie: the same position at the same company will pay different amounts depending on which US city it is located in).\n",
    "\n",
    "## <span style=\"color:limegreen\"> *for now, let's see what happens in we use label encoding* </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b3085420-82c5-4dcc-96cf-9411367dfbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# label_df = processed_df.copy()\n",
    "# label_df['job_title']= label_encoder.fit_transform(label_df['job_title'])\n",
    "# # label_df['employee_residence']=label_encoder.fit_transform(label_df['employee_residence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e799b9-6b1e-425c-b60d-2bcd10086e56",
   "metadata": {},
   "source": [
    "## <span style=\"color:limegreen\"> *okay lets try \"Bag of Words\" encoding job descriptions* </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14c91c68-3096-4e77-8a1f-4b72a4541e37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'scientist', 'machine', 'learning', 'big', 'engineer', 'product', 'analyst', 'lead', 'business', 'science', 'consultant', 'bi', 'director', 'of', 'research', 'manager', 'engineering', 'infrastructure', 'ml', 'ai', 'computer', 'vision', 'principal', 'head', '3d', 'researcher', 'analytics', 'applied', 'marketing', 'cloud', 'financial', 'software', 'developer', 'specialist', 'architect', 'finance', 'staff', 'etl', 'nlp']\n",
      "---\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "processed_df[\"job_title_clean\"] = processed_df[\"job_title\"].str.lower().apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "unique_words = (processed_df['job_title_clean']\n",
    "                .str.split()  # Split into words (by whitespace)\n",
    "                .explode()    # Create one row per word\n",
    "                .unique()    # Get unique values\n",
    "                .tolist())\n",
    "print(unique_words)\n",
    "print(\"---\")\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f67068-d8fb-4962-b687-28fe14431c46",
   "metadata": {},
   "source": [
    "It seems like there are still a lot of possible words in the job titles. Let's normalize a couple (\"ml\" -> \"machine\" and \"learning\", \"computer\" and \"vision\" -> \"computer_vision\"\n",
    "\n",
    "Then we will apply BoW encoding for the top 20 title-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ecd2f311-b790-4e92-b34c-1722235383fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kevinyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def normalize_terms(text):\n",
    "    \"\"\"\n",
    "    Replace specific terms/phrases before tokenization.\n",
    "    \"\"\"\n",
    "    # Convert \"ml\" to \"machine learning\" (case-insensitive)\n",
    "    text = re.sub(r'\\bml\\b', 'machine learning', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Combine \"computer vision\" as one term (handle with/without hyphen/space)\n",
    "    text = re.sub(r'\\bcomputer[-\\s]?vision\\b', 'computer_vision', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def get_word_frequency_df(df, column_name, min_count=0, custom_stopwords=None):\n",
    "    \"\"\"\n",
    "    Create a DataFrame of word frequencies with term normalization.\n",
    "    \"\"\"\n",
    "    # Combine all text, normalize terms, and lowercase\n",
    "    all_text = ' '.join(df[column_name].dropna().astype(str))\n",
    "    all_text = normalize_terms(all_text).lower()\n",
    "    \n",
    "    # Tokenize words (hyphen/underscore-aware)\n",
    "    words = re.findall(r'\\b[a-z_]+(?:\\-[a-z_]+)*\\b', all_text)  # Matches hyphenated/underscore terms\n",
    "    \n",
    "    # Get stopwords and add custom ones\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    if custom_stopwords:\n",
    "        stop_words.update([w.lower() for w in custom_stopwords])\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Filter words\n",
    "    filtered_counts = {\n",
    "        word: count for word, count in word_counts.items() \n",
    "        if word not in stop_words and count > min_count\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    word_df = (pd.DataFrame.from_dict(filtered_counts, orient='index', columns=['count'])\n",
    "               .reset_index()\n",
    "               .rename(columns={'index': 'word'})\n",
    "               .sort_values('count', ascending=False))\n",
    "    \n",
    "    return word_df\n",
    "\n",
    "word_freq_df = get_word_frequency_df(processed_df, 'job_title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "562a77d0-3581-4e8a-bb1f-beb2996ed3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_20_words = word_freq_df.head(20)['word'].tolist()\n",
    "\n",
    "\n",
    "def bow_encode(title, word_list):\n",
    "    title = title.lower()\n",
    "    features = {}\n",
    "    for word in word_list:\n",
    "        # Handle underscores (e.g., \"machine_learning\" → \"machine learning\")\n",
    "        search_term = word.replace('_', ' ')\n",
    "        features[f\"bow_{word}\"] = 1 if re.search(rf'\\b{search_term}\\b', title) else 0\n",
    "    return features\n",
    "\n",
    "# Apply to each job title and create a DataFrame\n",
    "bow_features = processed_df['job_title'].apply(lambda x: bow_encode(x, top_20_words)).apply(pd.Series)\n",
    "\n",
    "new_df = pd.concat([processed_df, bow_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c742bab1-e7aa-4b4a-a0df-8c4d0a4e1413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_level_EN</th>\n",
       "      <th>experience_level_EX</th>\n",
       "      <th>experience_level_MI</th>\n",
       "      <th>experience_level_SE</th>\n",
       "      <th>employment_type_CT</th>\n",
       "      <th>employment_type_FL</th>\n",
       "      <th>employment_type_FT</th>\n",
       "      <th>employment_type_PT</th>\n",
       "      <th>company_size_L</th>\n",
       "      <th>company_size_M</th>\n",
       "      <th>...</th>\n",
       "      <th>bow_principal</th>\n",
       "      <th>bow_architect</th>\n",
       "      <th>bow_computer_vision</th>\n",
       "      <th>bow_head</th>\n",
       "      <th>bow_director</th>\n",
       "      <th>bow_big</th>\n",
       "      <th>bow_applied</th>\n",
       "      <th>bow_ai</th>\n",
       "      <th>bow_engineering</th>\n",
       "      <th>employee_residence_mean_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.349970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.097936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.403512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.254701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.014835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experience_level_EN experience_level_EX experience_level_MI  \\\n",
       "0                   0.0                 0.0                 1.0   \n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   0.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 1.0   \n",
       "4                   0.0                 0.0                 0.0   \n",
       "..                  ...                 ...                 ...   \n",
       "560                 0.0                 0.0                 0.0   \n",
       "561                 0.0                 0.0                 0.0   \n",
       "562                 0.0                 0.0                 0.0   \n",
       "563                 0.0                 0.0                 0.0   \n",
       "564                 0.0                 0.0                 1.0   \n",
       "\n",
       "    experience_level_SE employment_type_CT employment_type_FL  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   1.0                0.0                0.0   \n",
       "2                   1.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   1.0                0.0                0.0   \n",
       "..                  ...                ...                ...   \n",
       "560                 1.0                0.0                0.0   \n",
       "561                 1.0                0.0                0.0   \n",
       "562                 1.0                0.0                0.0   \n",
       "563                 1.0                0.0                0.0   \n",
       "564                 0.0                0.0                0.0   \n",
       "\n",
       "    employment_type_FT employment_type_PT company_size_L company_size_M  ...  \\\n",
       "0                  1.0                0.0            1.0            0.0  ...   \n",
       "1                  1.0                0.0            0.0            0.0  ...   \n",
       "2                  1.0                0.0            0.0            1.0  ...   \n",
       "3                  1.0                0.0            0.0            0.0  ...   \n",
       "4                  1.0                0.0            1.0            0.0  ...   \n",
       "..                 ...                ...            ...            ...  ...   \n",
       "560                1.0                0.0            0.0            1.0  ...   \n",
       "561                1.0                0.0            0.0            1.0  ...   \n",
       "562                1.0                0.0            0.0            1.0  ...   \n",
       "563                1.0                0.0            0.0            1.0  ...   \n",
       "564                1.0                0.0            1.0            0.0  ...   \n",
       "\n",
       "    bow_principal bow_architect bow_computer_vision  bow_head bow_director  \\\n",
       "0               0             0                   0         0            0   \n",
       "1               0             0                   0         0            0   \n",
       "2               0             0                   0         0            0   \n",
       "3               0             0                   0         0            0   \n",
       "4               0             0                   0         0            0   \n",
       "..            ...           ...                 ...       ...          ...   \n",
       "560             0             0                   0         0            0   \n",
       "561             0             0                   0         0            0   \n",
       "562             0             0                   0         0            0   \n",
       "563             0             0                   0         0            0   \n",
       "564             0             0                   0         0            0   \n",
       "\n",
       "    bow_big bow_applied bow_ai bow_engineering employee_residence_mean_sal  \n",
       "0         0           0      0               0                   -0.349970  \n",
       "1         0           0      0               0                   -0.097936  \n",
       "2         1           0      0               0                   -0.403512  \n",
       "3         0           0      0               0                   -1.254701  \n",
       "4         0           0      0               0                    0.546751  \n",
       "..      ...         ...    ...             ...                         ...  \n",
       "560       0           0      0               0                    0.546751  \n",
       "561       0           0      0               0                    0.546751  \n",
       "562       0           0      0               0                    0.546751  \n",
       "563       0           0      0               0                    0.546751  \n",
       "564       0           0      1               0                   -1.014835  \n",
       "\n",
       "[565 rows x 45 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed50c6-8542-40c8-af5c-73e1908724b2",
   "metadata": {},
   "source": [
    "## <span style=\"color:limegreen\"> *lets try target encoding for the employee_residence column* </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3af970c1-cd0e-47c6-af16-9ca2f739449c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.426180\n",
       "1      2.068630\n",
       "2     -0.021966\n",
       "3     -1.254701\n",
       "4      0.545437\n",
       "         ...   \n",
       "560    0.600826\n",
       "561    0.213104\n",
       "562    0.254645\n",
       "563    0.545437\n",
       "564    1.237797\n",
       "Name: salary_in_usd, Length: 565, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['salary_in_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d244cf8-e3c2-4e69-9d48-ee07db2f4568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate mean salary per country for 'employee_residence'\n",
    "new_df['salary_in_usd'] = pd.to_numeric(new_df['salary_in_usd'])\n",
    "mean_employee_residence = new_df.groupby('employee_residence')['salary_in_usd'].mean().to_dict()\n",
    "new_df['employee_residence_mean_sal'] = new_df['employee_residence'].map(mean_employee_residence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "71b1cfab-11f9-4d92-9c7a-08657ce4888f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['job_title_clean'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-66391828d967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job_title_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 2. Convert all object columns to integers (with error handling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cse217a/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4311\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4312\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4313\u001b[0m         )\n\u001b[1;32m   4314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cse217a/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cse217a/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/cse217a/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5590\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5591\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['job_title_clean'] not found in axis\""
     ]
    }
   ],
   "source": [
    "\n",
    "new_df = new_df.drop(columns=['job_title_clean'])\n",
    "\n",
    "# 2. Convert all object columns to integers (with error handling)\n",
    "for col in new_df.select_dtypes(include=['object']).columns:\n",
    "    try:\n",
    "        new_df[col] = pd.to_numeric(new_df[col], errors='raise').astype(int)\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not convert column '{col}' to int: {e}\")\n",
    "        # Alternative: Convert to categorical codes if conversion fails\n",
    "        new_df[col] = new_df[col].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a10f6-0eab-4096-bab4-90551428357c",
   "metadata": {},
   "source": [
    "The last this to do before model building is to split the features from the target variable. As mentioned earlier, our target will be \"salary_in_usd\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba4f6a4a-2d0b-426d-a1cb-15f803b1ea79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = 'salary_in_usd'\n",
    "features = [col for col in new_df.columns if col not in target]\n",
    "\n",
    "# X = label_df[features]\n",
    "# y = label_df['salary_in_usd']\n",
    "\n",
    "X = new_df[features]\n",
    "y = new_df['salary_in_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab48ff-60f0-4a20-9dc3-b340b347eee0",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b463c97-af3c-4738-91b8-a6b7d7d2c1a5",
   "metadata": {},
   "source": [
    "We are going to fit our model using gradient descent, so let's start by implmenting a multivariate linear GD algorithm with MSE as the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60c5c4-3110-4ee2-9125-a9784aba2799",
   "metadata": {},
   "source": [
    "### Vanilla GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4a87df24-a2ab-4655-818e-84099c7076e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(grd_func, gamma, w0, N, tol=1e-05):\n",
    "    '''This function performs N-many iterations of gradient descent\n",
    "    \n",
    "    Args:\n",
    "        grd_func: the gradient of the function to minimize\n",
    "        gamma: the stepsize\n",
    "        w0: the starting x value/vector\n",
    "        N: the maximum number of iterations\n",
    "        (*) tol: the convergence tolerance\n",
    "\n",
    "    Output:\n",
    "        w: the final weight vector\n",
    "    '''\n",
    "\n",
    "    w = w0 # initialize w\n",
    "    \n",
    "    for n in range(N): # perform gradient descent N many times\n",
    "        grad = grd_func(w)\n",
    "\n",
    "        if np.linalg.norm(grad) < tol: # check if the function has converged (and return early if so)\n",
    "            print(f\"Converged!\\nIteration: {n}\")\n",
    "            return w\n",
    "\n",
    "        x_new = w - gamma*grad # gradient update rule\n",
    "        w = x_new #update w\n",
    "\n",
    "    print(f\"Did not converge...\\n Final Result: {w}\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac017283-73d2-441b-8d44-545b7009538e",
   "metadata": {},
   "source": [
    "For now, we are using vanilla GD (ie a constant stepsize), although we might want to consider updating this if convergence takes too long... Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7cdc038c-35a7-42d1-b705-5618d138819d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Until we figure out a way to encode job_title, salary_currency, employee_residence, and company_location, we will drop those columns...\n",
    "cols_to_drop = ['job_title', 'salary_currency', 'employee_residence', 'company_location']\n",
    "\n",
    "X_subset = X.drop(columns=cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9f24b9ee-daa2-4883-a93e-9f3d38957166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experience_level_EN              int64\n",
       "experience_level_EX              int64\n",
       "experience_level_MI              int64\n",
       "experience_level_SE              int64\n",
       "employment_type_CT               int64\n",
       "employment_type_FL               int64\n",
       "employment_type_FT               int64\n",
       "employment_type_PT               int64\n",
       "company_size_L                   int64\n",
       "company_size_M                   int64\n",
       "company_size_S                   int64\n",
       "work_year                        int64\n",
       "remote_ratio                     int64\n",
       "is_manager                       int64\n",
       "is_remote                        int64\n",
       "is_hybrid                        int64\n",
       "same_country                     int64\n",
       "bow_data                         int64\n",
       "bow_engineer                     int64\n",
       "bow_scientist                    int64\n",
       "bow_analyst                      int64\n",
       "bow_machine                      int64\n",
       "bow_learning                     int64\n",
       "bow_science                      int64\n",
       "bow_manager                      int64\n",
       "bow_research                     int64\n",
       "bow_analytics                    int64\n",
       "bow_lead                         int64\n",
       "bow_principal                    int64\n",
       "bow_architect                    int64\n",
       "bow_computer_vision              int64\n",
       "bow_head                         int64\n",
       "bow_director                     int64\n",
       "bow_big                          int64\n",
       "bow_applied                      int64\n",
       "bow_ai                           int64\n",
       "bow_engineering                  int64\n",
       "employee_residence_mean_sal    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f36d674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not converge...\n",
      " Final Result: [-0.01486895  1.3929511   0.25392868  0.51683905  0.9385712   0.17032283\n",
      "  0.56136875  0.4785871   0.50535044  0.37335352  0.27014592 -0.1693025\n",
      "  0.2559406  -0.51868861 -0.22926896 -0.36594056 -0.06682747 -0.08177644\n",
      " -0.15226334 -0.11588197 -0.50859516  0.05626862  0.05626862 -0.07025089\n",
      "  0.47464574  0.28668774 -0.09946633  0.87588797  1.1781831   0.34635936\n",
      " -0.12845881  0.27600506  0.85477263 -0.08017658  0.75361968  0.22238736\n",
      " -0.26031961  0.88984269 -0.85115012]\n",
      "w_star: [-0.01486895  1.3929511   0.25392868  0.51683905  0.9385712   0.17032283\n",
      "  0.56136875  0.4785871   0.50535044  0.37335352  0.27014592 -0.1693025\n",
      "  0.2559406  -0.51868861 -0.22926896 -0.36594056 -0.06682747 -0.08177644\n",
      " -0.15226334 -0.11588197 -0.50859516  0.05626862  0.05626862 -0.07025089\n",
      "  0.47464574  0.28668774 -0.09946633  0.87588797  1.1781831   0.34635936\n",
      " -0.12845881  0.27600506  0.85477263 -0.08017658  0.75361968  0.22238736\n",
      " -0.26031961  0.88984269]\n",
      "b_star: -0.8511501195467712\n"
     ]
    }
   ],
   "source": [
    "def f_linear(X, w, b):\n",
    "    return w.T @ X + b\n",
    "X_aug = np.hstack([X_subset, np.ones((X_subset.shape[0], 1))]) # adding a column for the bias term\n",
    "\n",
    "def grad_mse_linear(w_aug):\n",
    "    n = X_aug.shape[0]\n",
    "    return (2/n) * X_aug.T @ (X_aug @ w_aug - y)\n",
    "\n",
    "w0_aug = np.ones(X_aug.shape[1])\n",
    "\n",
    "# Run gradient descent\n",
    "w_star_aug = gradient_descent(grad_mse_linear, gamma=0.01, w0=w0_aug, N=100000)\n",
    "\n",
    "# Extract weights and bias\n",
    "w_star = w_star_aug[:-1]\n",
    "b_star = w_star_aug[-1]\n",
    "print(f'w_star: {w_star}')\n",
    "print(f'b_star: {b_star}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624768f2-2d5e-4611-b112-5f881fe1f2c0",
   "metadata": {},
   "source": [
    "Using vanilla GD is taking too long to converge. Thus, we should update the algorithm\n",
    "\n",
    "<span style=\"color:red\"> perhaps this is another thing to talk to Ben about. Is there standard practice for picking which gradient method to use?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a01b4-29af-4080-878d-d2f5c4a5a92c",
   "metadata": {},
   "source": [
    "### SGD (mini-batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "651885cb-c4b7-451f-a814-43cfc50febbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stochastic_gd(grd_func, gamma, w0, X, y, N, batch_size, tol=1e-5):\n",
    "    '''This function performs N-many iterations of stochastic gradient descent (SGD) for a model.\n",
    "    \n",
    "    Args:\n",
    "        grd_func: the gradient of the function to minimize\n",
    "        gamma: the stepsize\n",
    "        w0: the starting weight vector\n",
    "        X: the input data (Pandas DataFrame)\n",
    "        y: the output data (numpy array)\n",
    "        N: maximum number of iterations\n",
    "        batch_size: size of mini-batch for each SGD update\n",
    "        (*) tol: convergence tolerance\n",
    "\n",
    "    Output:\n",
    "        w: final weight vector after training\n",
    "    '''\n",
    "    n = X.shape[0]  # number of samples\n",
    "    w = w0  # initialize weight vector\n",
    "\n",
    "    for i in range(N):\n",
    "        # Shuffle data\n",
    "        indices = np.random.permutation(n)\n",
    "        X_shuffled = X[indices,:]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        for j in range(0, n, batch_size):\n",
    "            X_batch = X_shuffled[j:j + batch_size,:]\n",
    "            y_batch = y_shuffled[j:j + batch_size]\n",
    "\n",
    "            # Compute gradients using the user-defined gradient function\n",
    "            grad = grd_func(w, X_batch, y_batch)\n",
    "\n",
    "            # Update weights using the gradient and learning rate\n",
    "            w_new = w - gamma * grad\n",
    "            w = w_new\n",
    "\n",
    "        # Convergence check (optional early stopping)\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            print(f\"Converged!\\nEpoch: {i}\")\n",
    "            return w\n",
    "\n",
    "    print(f\"Did not converge...\\nFinal Result: {w}\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "49cc9747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not converge...\n",
      "Final Result: [ 0.05348536  1.46166506  0.32107977  0.5828616   1.00568508  0.23887639\n",
      "  0.62907649  0.54545384  0.59443099  0.46313825  0.36152255 -0.16683236\n",
      "  0.16623192 -0.51728671 -0.14007761 -0.27459868 -0.06764125 -0.08420403\n",
      " -0.15503047 -0.11868368 -0.51082671  0.05594761  0.05594761 -0.07204006\n",
      "  0.4766052   0.28324074 -0.10359077  0.87724616  1.18043806  0.34193661\n",
      " -0.1350558   0.27409086  0.85477107 -0.08136638  0.7507038   0.22196415\n",
      " -0.26355959  0.88791162 -0.58090821 -0.58090821]\n",
      "w_star: [ 0.05348536  1.46166506  0.32107977  0.5828616   1.00568508  0.23887639\n",
      "  0.62907649  0.54545384  0.59443099  0.46313825  0.36152255 -0.16683236\n",
      "  0.16623192 -0.51728671 -0.14007761 -0.27459868 -0.06764125 -0.08420403\n",
      " -0.15503047 -0.11868368 -0.51082671  0.05594761  0.05594761 -0.07204006\n",
      "  0.4766052   0.28324074 -0.10359077  0.87724616  1.18043806  0.34193661\n",
      " -0.1350558   0.27409086  0.85477107 -0.08136638  0.7507038   0.22196415\n",
      " -0.26355959  0.88791162 -0.58090821]\n",
      "b_star: -0.5809082069698931\n"
     ]
    }
   ],
   "source": [
    "def sgd_grad_linear_mse(w, X_batch, y_batch):\n",
    "    X_aug = np.hstack([X_batch, np.ones((X_batch.shape[0], 1))])  # Adding bias as the last column\n",
    "    n = len(X_aug)\n",
    "        \n",
    "    y_pred = X_aug @ w\n",
    "    error = y_batch - y_pred\n",
    "    \n",
    "    return -(2/n) * X_aug.T @ error  # gradient with respect to w (including bias)\n",
    "\n",
    "w0_aug = np.ones(X_aug.shape[1]+1)\n",
    "\n",
    "w_star_aug = stochastic_gd(sgd_grad_linear_mse, gamma=0.01, w0=w0_aug, X=X_aug, y=y, N=100000, batch_size=25)\n",
    "\n",
    "# Extract weights and bias\n",
    "w_star = w_star_aug[:-1]\n",
    "b_star = w_star_aug[-1]\n",
    "print(f'w_star: {w_star}')\n",
    "print(f'b_star: {b_star}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f1efd",
   "metadata": {},
   "source": [
    "### AGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e7e7b7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accelerated_gd(grd_func, gamma, w0, N, momentum=0.9, tol=1e-05):\n",
    "    '''This function performs N-many iterations of momentum-based gradient descent\n",
    "    \n",
    "    Args:\n",
    "        grd_func: the gradient of the function to minimize\n",
    "        gamma: the stepsize\n",
    "        w0: the starting x value/vector\n",
    "        N: the maximum number of iterations\n",
    "        (*) momentum: the momentum parameter (usually between 0 and 1)\n",
    "        (*) tol: the convergence tolerance\n",
    "\n",
    "    Output:\n",
    "        w: the final weight vector\n",
    "    '''\n",
    "\n",
    "    w = w0\n",
    "    v = np.zeros_like(w0)  # initialize velocity (same shape as w0)\n",
    "    \n",
    "    for n in range(N):\n",
    "        grad = grd_func(w)\n",
    "\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            print(f\"Converged!\\nIteration: {n}\")\n",
    "            return w\n",
    "\n",
    "        v = momentum * v - gamma * grad\n",
    "        w = w + v \n",
    "\n",
    "    print(f\"Did not converge...\\n Final Result: {w}\")\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce1c879b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged!\n",
      "Iteration: 13176\n",
      "w_star: [-0.01431122  1.39356285  0.25440479  0.51739103  0.93872312  0.17136587\n",
      "  0.56192314  0.47903531  0.50611434  0.37411987  0.27081324 -0.16929021\n",
      "  0.25517456 -0.51940712 -0.22851653 -0.36526147 -0.06705932 -0.08385855\n",
      " -0.15470895 -0.11831094 -0.51109861  0.05512345  0.05512345 -0.07192446\n",
      "  0.47456307  0.28435558 -0.10109257  0.87662969  1.17818014  0.34351852\n",
      " -0.13132437  0.27468874  0.85471139 -0.0802301   0.75363027  0.21957225\n",
      " -0.26248149  0.88981469]\n",
      "b_star: -0.8489525557829253\n"
     ]
    }
   ],
   "source": [
    "def f_linear(X, w, b):\n",
    "    return w.T @ X + b\n",
    "\n",
    "X_aug = np.hstack([X_subset, np.ones((X_subset.shape[0], 1))]) # adding a column for the bias term\n",
    "\n",
    "def grad_mse_linear(w_aug):\n",
    "    n = X_aug.shape[0]\n",
    "    return (2/n) * X_aug.T @ (X_aug @ w_aug - y)\n",
    "\n",
    "w0_aug = np.ones(X_aug.shape[1])\n",
    "\n",
    "# Run gradient descent\n",
    "w_star_aug = accelerated_gd(grad_mse_linear, gamma=0.01, w0=w0_aug, N=100000)\n",
    "\n",
    "# Extract weights and bias\n",
    "w_star = w_star_aug[:-1]\n",
    "b_star = w_star_aug[-1]\n",
    "print(f'w_star: {w_star}')\n",
    "print(f'b_star: {b_star}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc947cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
